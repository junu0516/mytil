## 컴퓨터에서의 프로세스와 스레드

- __`프로세스`__ : 운영체제로부터 자원을 할당받은 작업의 단위를 의미하며, 직관적으로 이해하자면 '실행중인 프로그램'을 프로세스로 여기면 됨
  - 일반적인 프로그램은 단순한 코드 덩어리이며, 운영체제로부터 자원을 할당받아 메모리에 올라가 실행 가능한 상태가 되면 프로세스라 부를 수 있는 것
  - 프로세스의 동작은 결국, CPU가 프로세스에서 내린 명령을 실행하는 것으로 요약할 수 있음
  - 운영체제는 프로세스의 생성과 종료를 위한 작업과 프로세스를 실행시키기 위한 스케줄링 작업을 처리하며, 여기서 스케줄러에 의한 자원 할당을 __`디스패치(Dispatch)`__ 라고 표현
- 프로그램 실행을 위해 사용자가 이를 더블클릭하면(GUI 환경이라고 가정) 운영체제에 해당 프로그램을 실행하도록 요청하는 것이며, 운영체제는 프로그램의 정보를 읽고 실행하기 위해 메인 메모리에 실행을 위한 공간을 할당해줌
- 이런 식으로 운영체제에 의해 할당받은 프로세스의 메모리 구조는 크게 __`스택`__ , __`힙`__ , __`코드`__ , __`데이터`__ 영역으로 나눠볼 수 있음
  - 스택 영역은 지역변수나 매개변수, 리턴값 등 함수 호출과 관계 되는 데이터가 일시적으로 저장되는 영역으로 컴파일 시점에 보통 함수 호출에 대한 정보를 기반으로 사이즈가 미리 결정됨
  - 함수가 호출될 때 스택 영역에 데이터가 올라가는 것이며, 함수의 실행 종료와 함께 올라간 데이터는 스택 영역에서 해제됨(push & pop)
  - 만일 런타임 시점에 지나치게 함수 호출이 많아서 전체 데이터의 크기가 미리 정해진 스택 영역을 벗어나게 되면 __`Stack Overflow`__ 가 발생
  - 힙 영역은 동적으로 할당되는 인스턴스 혹은 참조 변수가 저장되는 영역이며, 스택과 달리 런타임 시점에 어떤 데이터가 올라갈 지 예측 불가능하기 때문에 동적 할당이라고 표현하는 것
  - 메모리의 누수를 방지하기 위해, 더 이상 사용하지 않는 메모리 공간은 반드시 할당 해제되야 함

- __`스레드`__ : 단일 프로세스 내부에서 작업의 다중 처리를 위해 사용되는 프로세스 보다 한 단계 더 낮은 실행 단위 개념
  - 프로그램이 복잡해질수록 단순히 하나의 프로세스만 가지고 이를 실행시키기는 힘들며, 그렇다고 해서 하나의 프로그램 실행을 위해 여러 프로세스를 생성하는 것은 __`문맥 교환(Context Switching)`__ 으로 인한 부담 등으로 인해 사실상 비효율적이므로 스레드 개념이 필요한 것
- 스레드는 개수에 따라 __`싱글 스레드`__ 와 __`멀티 스레드`__ 로 나눠볼 수 있으며, 프로세스를 __자원 소유의 단위(unit of resource ownership)__ 과 **자원 할당(디스패칭)의 단위(unit of dispatching)** 의 두 가지 측면으로 볼 수 있다면 스레드는 후자의 개념에 포함된다고 보면 됨
  - 다시 말해, 멀티 스레딩 환경을 가정했을 때 전체 자원을 하나의 프로세스가 소유한 상태에서 내부의 여러 스레드가 사용할 자원을 분배받는 상황을 의미하는 것
- 보통 스레드는 프로세스에서 __실행의 개념__ 만을 분리한 것이기 때문에, 실행에 필요한 최소한의 정보만을 가진 채로 작업을 수행하며 필요하면 프로세스의 실행 환경을 여러 스레드가 공유함
  - 보통 여러 스레드가 독립적인 스택 영역을 프로세스로부터 할당받고, 나머지 메모리 영역은 서로 공유하는 형태임
  - 이는 다시 말해, 한 스레드가 프로세스 내에서 다른 스레드와 공유하는 영역에 위치한 데이터를 변경할 경우에는 다른 스레드의 작업에 영향을 끼칠 수 있음을 의미

​    

## 동기와 비동기, 동시성과 병렬성의 개념적 차이

### 동기 & 비동기

- __`동기적(Synchronous)`__ : 이전에 진행 중이던 작업이 끝나야 이후의 작업을 진행하는, 일련의 순차적 과정을 지키는 것을 의미

- __`비동기적(Asynchronous)`__ : 작업의 순서를 보장하지 않고, 이전의 작업이 끝나기 전에 이후의 작업을 먼저 시작하는 것이 가능한 상황을 의미

- 단일 프로세스 내에서 싱글 스레드로 동작하는 환경, 즉 메인 스레드로만 실행하는 환경이라면 대부분 병렬 처리가 불가능하기 때문에 코드를 동기적으로 실행하게 됨

- 동시성 혹은 병렬성 개념을 적용할 수 있는 상황이라면 코드를 비동기적으로 실행하는 것이 가능해짐

  

### 동시성 & 병렬성

- __`동시성(Concurrency)`__ : 한 번에 여러 작업을 처리해서, 마치 동시에 여러 작업이 실행된 것 처럼 보이게 하는 것
- 여러 프로세스는 동시적으로 처리되기 위해 __`문맥교환(Context Switching)`__ 을 통해 자원을 번갈아가며 할당받으며, 여기서 자원을 양보하는 프로세스는 이전까지의 상태 정보를 __`프로세스 제어블록(PCB)`__ 에 기록해두는 형태임
- __`병렬성(Parallelism)`__ : 실제로 동시에 여러 작업이 처리되는 것을 의미함
  - 보통 __`simultaneously`__ 라는 개념은 동시성이 아닌 병렬성에 대한 것
- 둘의 차이는 결국 __논리적으로 작업을 동시적으로 처리하는 것과, 실제 물리적으로 작업이 동시에 처리된다는 데 있음__
- __`동시성`__ 은 __싱글 코어 환경에서 멀티 스레딩이 가능한 방식__ 과 관련이 있고, __`병렬성`__ 은 __멀티 코어 환경에서 멀티 스레딩이 가능한 방식__ 과 관련이 있음
- __`동시성`은 `병렬성`을 만족하기 위한 필요조건이지만 충분조건은 아님__
  - __`병렬성 만족 -> 동시성 만족`__ 은 성립하지만, 동시성 만족 -> 병렬성 만족 은 항상 성립하는 것이 아닌 것
- 보통 __`코어(Core)`__ 라고 하면, CPU의 연산을 담당하는 핵심 부품 정도로 이해하면 되며 오늘날에는 코어의 개수가 늘어날 수록 처리할 수 있는 작업의 양이 많아질 뿐만 아니라 이에 비례하여 성능도 더 좋아짐
  - 엄밀히 말해 멀티 코어라고 해서 무조건 성능이 좋아지는 것이 아니라, 원래는 클럭 증가에 따른 발열이슈로 인해 오히려 멀티 코어에서 처리할 수 있는 작업의 양이 많지 않았지만 이러한 부분이 개선되면서 멀티 코어 환경에서 더 많은 작업을 처리할 수 있는 수준으로 발전한 것
- __`멀티 코어(Multi Core)`__ 환경에서는 다수의 코어를 활용한 병렬 처리가 가능해지는데, 각 코어가 하나 이상의 스레드를 포함하여 작업을 물리적으로 동시에 처리하는 것임
  - 단, 병렬 처리는 자동으로 처리되는 것이 아니라 스레드의 생성 및 기타 동기화작업 등의 수행을 해줘야 하는 것
  - __병렬 처리의 핵심은 다수의 작업이 물리적으로 동시에 실행되는 것이 핵심__ 이며 멀티 코어 및 멀티 스레딩 환경이라고 해서 항상 병렬 처리를 담보한다고 볼 수는 없음
  - 만일 멀티 스레딩 환경에서 다수의 작업을 진행하더라도 서로가 자원을 번갈아 가며 할당받고 물리적으로 동시에 실행되지 않는다면 병렬성을 만족시키지 못한 것
- __`싱글 코어`__ 에서의 멀티스레딩은 엄밀히 말해 여러 스레드가 번갈아가며 작업들을 처리함으로서 __`동시성`__ 을 만족시킬 수 있음
  - 단, 멀티 스레딩이 가능한 환경에서만 반드시 동시성을 충족할 수 있는 것은 아니며 __싱글 스레드 환경에서도 동시성을 만족시킬 수 있음__
  - 싱글 코어 및 싱글 스레드 환경에서 2개의 작업이 서로 번갈아가면서 자원을 할당받으며 진행되는 경우에도 동시성을 만족시킬 수 있음
  - Kotlin의 코루틴 개념이 싱글코어, 싱글 스레드에서 동시성을 만족시키는 것임

​    

## 동시성 문제와 Thread-Safety

- 만일 동시성이 만족되는 멀티 스레딩 환경에서 여러 스레드가 공유 자원에 동시에 접근하는 경우 혹은 동일한 메모리 영역에 접근하는 경우에 여러 __`동시성 문제`__ 가 발생할 수 있음

- 보통 멀티 스레딩 환경에서 특정 자원에 여러 스레드가 동시다발적으로 접근해도 프로그램의 실행에 아무런 논리적 문제가 발생하지 않는 경우를 __`Thread-safe`__ 한 상황이라고 부르며, __`동시성 문제`__ 가 발생하는 상황은 곧 __`Thread-safe`__ 하지 않은 상황인 것

- __`동시성 문제`__ 의 대표적인 케이스로 __`경쟁 상태(Race Condition)`__ 과 __`교착 상태(Deadlock)`__ 를 들 수 있음
- __`경쟁 상태(Race Condition)`__ : 여러 프로세스 혹은 스레드가 공유 자원에 동시에 접근하고자 할 때, 자원의 __`일관성(Consistency)`__ 을 해치는 등의 부작용을 야기할 수 있는 상황
  - Xcode의 경우 Thread Sanitizer을 통해 경쟁 상태가 발생할 수 있는 코드를 확인할 수 있음
  - 경쟁 상태를 해결하기 위해서는 결국 __공유 자원에 대한 접근을 순차적으로 처리__ 하도록 하면 됨
  - __`동기화(Synchronization)`__ 를 통해 무분별하게 공유자원에 여러 스레드가 동시에 접근하지 못하도록 하는 것 
- __`교착 상태(Deadlock)`__ : 한정된 자원을 여러 프로세스나 스레드가 동시에 할당받고자 할 때, 어느 것도 자원을 얻지 못해서 다음 작업이 처리되지 않는 상황
  - 교착상태의 해결은 보통 이를 사전에 방지하거나, 교착 상태 발생 후 처리하는 방식이 있음
  - 교착상태를 사전에 방지하고자 할 경우에는 일반적으로 아래의 교착상태가 발생하기 위한 4가지 필요조건 중 하나라도 충족되지 않도록 함
    - 상호배제 : 하나 이상의 프로세스가 임계영역에 진입하면 다른 프로세스가 이에 접근할 수 없음
    - 점유대기 : 특정 프로세스에 할당된 자원을 다른 프로세스가 이 자원을 할당받고 싶으면, 자원이 해제될 때 까지 대기해야 함
    - 비선점 : 특정 프로세스에 할당된 자원은 해당 프로세스가 이를 반납하기 전까지는 해제되지 않음
    - 환형대기 : 자원 할당 및 자원에 대한 요구 관계가 환형 상태를 이룸

  - 교착상태의 해결은 [여기](https://github.com/junu0516/mytil/blob/main/Operating_System/%EA%B5%90%EC%B0%A9%EC%83%81%ED%83%9C.md) 에 간단히 정리해뒀음

​    

### 뮤텍스와 세마포어

- __`임계 영역(Critical Section)`__ : 여러 프로세스 혹은 스레드가 작업을 수행하면서 공유하는 자원에 접근하는 부분을 임계영역이라 부름

- 임계 영역에 여러 스레드가 동시다발적으로 접근하면 __`동시성 문제`__ 가 발생할 수 있기 때문에, 동기화 처리를 잘 해야 하는데 대표적인 방식으로 __`뮤텍스`__ 와 __`세마포어`__ 라는 개념을 사용

- __`세마포어(Semaphore)`__ : 공유자원에 여러 프로세스 혹은 스레드가 동시에 접근하는 것을 막기 위해, 공유 자원의 현재 사용 가능 여부를 나타내는 카운터 변수를 사용하여 허용된 상황에만 공유 자원에 접근할 수 있도록 하는 방식

  - iOS의 경우 후술할 GCD를 사용하여 비동기 처리할 때, __`DispatchSemaphore`__ 라는 것을 사용하여 한 번에 사용할 수 있는 작업의 수를 제한할 수도 있음
  - 개수를 제한하고, 임계영역에 들어갈 때 __`wait()`__ , 나올 때 __`signal()`__ 을 각각 호출하여 카운터 변수를 조작하는 것

  ```swift
  let semaphore = DispatchSemaphore(value: 2) //2개로 제한
  for i in 0...2 {
    semaphore.wait() //세마포어 감소
    DispatchQueue.global().async() {
      //임계영역 설정
      print("공유 자원에 대한 접근")
      semaphore.signal() //세마포어 증가
    }
  }
  ```

- __`뮤텍스(Mutex)`__ : 상호 배제를 의미하는 말로, 임계 영역에 하나의 프로세스 혹은 스레드만이 접근하도록 하는 방식임

  - 세마포어는 카운터 변수의 설정에 따라 여러 스레드가 접근할 수도 있지만, 뮤텍스는 반드시 하나만 접근하도록 했다는 점이 다름
  - Lock, Unlock 개념을 사용하여, Lock 상태가 되면 다른 스레드가 임계영역에 접근하지 못하도록 하는 것이 대표적인 방식


​    

## 스위프트에서의 비동기 처리 방법

### OperationQueue

- 작업(Operation)을 정의하여 OperationQueue에 넣어 비동기처리하는 방식
- Operation을 상속받는 작업 클래스를 따로 정의해도 되고, 클로저를 OperationQueue에 추가시켜 작업을 정의할 수도 있음

```swift
//작업 정의
class CustomOperation: Operation{

  override func main() {
    //Operation에서 수행할 작업 정의
    Thread.sleep(forTimeInterval: Double(coffee!.time!))
  }
}
```

```swift
class CustomOperationQueues{

  var operationQueues: [OperationQueue] = []

  func setOperationQueueNum(_ num: Int){
    for _ in 0..<2{
      let operationQueue: OperationQueue = OperationQueue()
      //각 큐에 스레드 개수 할당
      operationQueue.maxConcurrentOperationCount = 2
      operationQueues.append(operationQueue)
    }
  }

  //작업 큐에 작업 추가
  func addOperation(_ customOperation: CustomOperation){
    for i in 0..<operationQueues.count {
      if(operationQueues[i].operationCount<2){
        operationQueues[i].addOperation(customOperation)
        break
      }
    }
  }
}
```

- 위의 코드는 __`Operation`__ 을 상속받는 작업 클래스를 따로 정의한 후, 이를 __`OperationQueue`__ 에 __`addOperation()`__ 을 통해 작업을 추가하였음
- __`maxConcurrentOperationCount`__ 를 통해 한 번에 동시적으로 처리할 작업의 수를 원하는 대로 조정할 수도 있음
- __`Operation`__ 을 상속받는 작업 클래스는 내부에 __`main()`__ 메소드를 오버라이딩해서, 각 작업이 구체적으로 어떤 로직을 수행할 것인지를 정의해야 함
- 작업 큐의 생성, 작업의 추가, 스레드의 개수 지정 등 개발자가 여러 부분을 직접 정의해야 하기 때문에 어떻게 보면 번거롭지만, 그만큼 직접 정의한 부분에 대해서는 비교적 쉽게 통제할 수 있다는 이점이 있음
- 또한 [Operation 레퍼런스](https://developer.apple.com/documentation/foundation/operation) 에 나와있듯이, 여러 속성 및 메소드를 오버라이딩함으로서 각 스레드가 처리하는 작업의 상태를 관리할 수도 있음

​    

### GCD(Grand Central Dispatch)

- macOS 혹은 iOS 환경에서 __`암묵적 스레딩(Implicit Threading)`__ 을 구현한 기술로 __`DispatchQueue`__ 라 불리는 작업 큐에 비동기적으로 실행시킬 작업을 넣고, 이를 각 스레드에 할당시켜 작업을 처리하는 것
  - __`암묵적 스레딩`__ : 스레드의 생성 및 관리에 대한 책임을 개발자가 아닌 라이브러리나 컴파일러에 넘기는 것을 의미함
  - 멀티 코어 환경이 갈수록 복잡해지면서, 단일 어플리케이션이 포함하는 스레드의 수가 매우 많기 때문에 이를 개발자가 온전히 관리하는 것은 사실상 부담스러우므로 책임을 넘기는 것
  - 암묵적 스레딩 환경에서 개발자에게 주어진 책임은, 어플리케이션이 관리하는 스레드가 수행할 작업을 정의하는 것으로 압축됨
  - GCD를 포함한 암묵적 스레딩 환경에서는 보통 일정한 양의 스레드를 미리 만들어 놓고 이후 멀티 스레딩 수행 시에 __`Thread Pool`__ 에 있는 유효한 스레드를 꺼내 여기에 작업을 부여하는 방식이라고 보면 됨
  - 만일 개발자가 아무런 제한 없이 스레드를 많이 만들 경우에는, 일정 시점 부터는 스레드의 수가 너무 많아서 동시성 처리 시에 스레드 간 문맥 교환으로 인한 비용이 너무 커지기 때문에 오히려 비효율적인 상황이 발생하기 때문  --> 따라서 미리 적정량의 스레드를 만들어놓고 이 안에서 효율적으로 돌려 쓰는 것!
- GCD의 스레드 풀에서 관리하는 스레드는 기본적으로 POSIX Thread로, 이는 유닉스 호환 스레드를 의미하며 macOS 환경에 UNIX기반의 운영체제임을 생각하면 됨
- 위에서 언급한 OperationQueue와의 제일 큰 차이는, OperationQueue가 작업을 __`Operation`__ 을 상속받은 인스턴스 형태로 '객체화' 하였다면, GCD는 작업을 클로저 단위로 좀 더 간소하게 표현했다는 점에 있음
- GCD가 관리하는 큐는 **`Concurrent Queue`** 와 **`Serial Queue`** 의 두 종류로 나뉘는데, 전자가 동시성 처리를 위한 것이라면 후자는 직렬이라는 단어 의미 그대로 순차적인 작업 처리를 위한 것으로 이해하면 됨

#### Serial Queue & Main Queue

- 보통 직렬 큐로 들어온 작업은 선입선출로 제거되며, 큐에서 제거된 작업은 다음 작업에 큐에서 제거되기 전에 수행되야 함
- 보통 각 프로세스는 메인 스레드 위에서 동작하는 메인 큐(__`Main Queue`__) 라고 불리는 자신만의 직렬 큐를 우선적으로 가짐

```swift
//아래 2가지 작업에 대한 순서가 보장됨
DispatchQueue.main.async {
  print("hello1")
}

DispatchQueue.main.async {
  print("hello2")
}

RunLoop.main.run()
```

- 굳이 메인 큐가 아니더라도, 개발자가 원할 경우에는 원하는 이름을 붙인 직렬 큐를 추가로 생성할 수도 있음

```swift
let addit = DispatchQueue(label: "temp")
// 아래 3가지 작업에 대한 순서가 보장됨
addit.async {
  print("hello1")
}

addit.async {
  print("hello2")
}

addit.async {
  print("hello3")
}
```

#### Concurrent Queue & Global Queue

- 동시성 큐는 직렬 큐와 달리 작업을 동시적으로 분산 처리하기 때문에, 위의 코드들과 달리 작업의 순서를 보장하지 않음
- 직렬큐와 동일하게 선입선출로 작업을 큐에서 제거하지만, 멀티 스레딩 환경에서는 여러 작업이 동시에 큐에서 한 번에 제거될 수 있음
  - 다시 말해, 병렬적인 처리가 가능하다는 것

```swift
let addit = DispatchQueue(label: "temp", attributes: .concurrent)
//아래 3가지 작업에 대한 순서가 보장되지 않음
addit.async {
  print("hello1")
}

addit.async {
  print("hello2")
}

addit.async {
  print("hello3")
}

print("hey")
```

- 위의 코드의 경우에는 동시성 큐를 직접 만들었지만, 보통은 __`qos(quality of service)`__ 에 따라 약 6종류의 동시성 큐를 기본적으로 제공하며 이를 __`Global Queue`__ 라고 부름
  - qos는 작업의 중요도 정도로 생각하면 되며, 중요도에 따라 userInteractive, userInitiated, default, utility, background, unspecified 순으로 중요도가 높음

```swift
//아래 2가지 작업에 대한 순서가 보장되지 않음
DispatchQueue.global(qos: .background).async {
  print("hello1")
}

DispatchQueue.global(qos: .background).async {
  print("hello2")
}
```

 #### sync & async

- __`sync`__ , __`async`__ 는 결국 작업을 동기적으로 처리할 지, 비동기적으로 처리할 지를 결정하는 것임
- 동기적으로 작업을 처리한다는 것은, 큐에 작업을 추가한 후 이것이 끝날 때 까지 기다리겠다는 것을 의미함
  - 단, 메인 큐의 경우 sync로 작업을 처리하면 교착상태가 발생하기 때문에 절대 사용하면 안됨(이유는 후술)
- 동일한 동시성 큐에 여러 작업을 넣고 sync로 각각 호출할 경우에는 각 작업을 동기적으로 호출하기 때문에 직렬큐를 사용하여 작업의 순서를 보장하는 것과 같은 결과가 나타남

```swift
let concurrentQueue = DispatchQueue(label: "temp", attributes: .concurrent)
// 아래 3가지 작업에 대한 순서가 보장됨
concurrentQueue.sync {
  print("hello1")
}

concurrentQueue.sync {
  print("hello2")
}

concurrentQueue.sync {
  print("hello3")
}

RunLoop.main.run()
```

- 직렬큐에 작업을 넣고 이를 sync로 호출하여 동기적으로 처리하면 결국 클로저 형태로 넘긴 작업이 끝날 때 까지 대기하기 때문에 임계영역을 지정하는 것과 같은 효과를 나타낼 수도 있음

```swift
func updateImageCache(_ image: UIImage) {
  DispatchQueue.init(label:"someSerialQueue").sync{
    //Criticial Section begin
  }
}
```

​    

## 스위프트에서 GCD 사용 시에 고려해야할 것들

### UI 이벤트는 메인 스레드에서만 실행되도록 해야 함

- 만일 UI 관련 작업을 큐에 넣는 경우라면 메인 큐에 넣어서 메인 스레드에서 실행되도록 해야 함
- 일단 UIKit의 여러 속성은 Thread-safe 하게 구현되어있지 않으며, __`RunLoop.main`__ 가 뷰의 업데이트를 관리하도록 설계되있는데 여기서 메인 스레드 외의 다른 스레드가 각자의 __`RunLoop`__ 를 가지고 업데이트를 하면 결국 뷰가 제멋대로 동작하는 결과를 초래함
- 그렇다고 UIKit의 모든 속성을 Thread-safe하게 설계하면, 화면 업데이트 자체가 느려지는 등의 성능저하가 있기 때문에 애플에서는 Thread-safe 하지 않게 설계한 것임
- 또한 iOS 환경에서 뷰를 그리는 렌더링 과정은 일련의 절차를 따라야 하는데, 멀티 스레드 환경에서 각 스레드가 각자의 변경사항을 GPU로 보내버리면 GPU가 동시적으로 들어오는 여러 업데이트 정보를 일일히 해석해야 하기 때문에 성능상 비효율적인 결과를 초래할 것

​    

### Race Condition의 발생

```swift
var sharedValue = 0
let valueGroup = DispatchGroup()

DispatchQueue.global(qos: .background).async(group: valueGroup) {
    sharedValue = 100 // 쓰기
    print("background after", sharedValue) // 읽기
}

DispatchQueue.global(qos: .userInteractive).async(group: valueGroup) {
    sharedValue = 200 // 쓰기
    print("userInteractive after", sharedValue) // 읽기
}

valueGroup.notify(queue: DispatchQueue.main) {
    print("final: ", sharedValue)
}
```

- 위의 상황은 sharedValue라는 변수에 여러 스레드(background, userInteractive)가 동시에 접근해서 쓰기와 읽기를 하는 상황으로 **`Race Condition`** 이 발생하는 상황임
- sharedValue의 일관성이 보장되지 못하기 때문에 Thread-Safe하지 못한 상황임
- 우선 Serial Queue를 사용해서, 읽기와 쓰기를 아래와 같이 순차적으로 처리할 수 있음(**`DispatchQueue().sync`**)

```swift
let serialQueue = DispatschQueue(label: "serial")
var sharedValue = 0

DispatchQueue.global(qos: .background).async {
    serialQueue.sync {
        sharedValue = 100
    }
    serialQueue.sync {
        print("background queue \(sharedValue)")
    }
}

DispatchQueue.global(qos: .userInteractive).async {
    serialQueue.sync {
        sharedValue = 200
    }
    serialQueue.sync {
        print("userInteractive queue \(sharedValue)")
    }
}
```

- 단, background queue와 userInteractive queue 의 쓰기 결과는 매 번 코드를 돌릴때마다 달라지게 됨

- 각각의 큐 내부에서 읽기와 쓰기는 순차적으로 일어나기 때문에 Thread-Safe하게 보일 수 있지만, 한 큐의 읽기와 쓰기 사이에 다른 큐의 읽기나 쓰기 작업이 먼저 들어갈 수 있기 때문

  <img src="https://camo.githubusercontent.com/e2fe632fafa895f7f453a9d3cc50b67c826021891e1da1eca841b65dbf9de178/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f343039322f312a756d4431574b5143326d5f6d6872574c4d41515555772e706e67" alt="img" style="zoom:33%;" />

  결론적으로 sharedValue에 대한 접근은 한 번에 하나의 스레드만 접근할 수 있지만 background Queue와 userInteractive Queue의 작업 순서를 알 수 없기 때문에 콘솔에 출력되는 결과는 매번 다른 것



### Deadlock의 발생

> 프로세스나 스레드가 자원을 할당받지 못해서 작업을 수행하지 못하는 상황

- 대표적으로 **처리하고자 하는 작업이 속한 큐와 동일한 큐에 동기적으로 `sync` 로 작업을 보내는 경우** 에 교착상태가 발생할 수 있음
- 비동기적으로 처리해야 할 작업 전체가 특정 스레드에 할당된 상태에서, 해당 작업 내부에서 동일한 큐에 동기적으로 처리하도록 선언된 작업이 동일한 스레드에 할당된 경우 교착상태가 발생하는 것

```swift
DispatchQueue.global().async{
  DispatchQueue.global().sync{
    print("Task in sync queue")
  }
}
```

- **`async`** 로 처리할 작업 전체가 우선 특정 스레드에 할당된 상태에서, 내부에 **`sync`** 로 처리할 작업이 동일한 스레드에 할당되면서 **`async` 작업 전체는 `sync` 작업이 끝날 때 까지 스레드 자원을 반납하지 않고, `sync` 작업은 스레드 자원을 점유중인 `async` 작업을 계속해서 기다리는 상황이 되는 것**
- 따라서 교착상태의 발생을 막기 위해서 비동기 처리 시에 동일한 큐에 **`sync`** 작업을 보내지 않도록 주의해야 함
- 혹은 동일한 큐라 하더라도 **`qos`** 를 달리함으로써, 스레드가 겹치는 상황을 방지하는 식으로도 교착상태를 막을 수 있음

```swift
DispatchQueue.global(qos: .utility).async{
  DispatchQueue.global().sync{
    print("Task in sync queue")
  }
}
```

- 위의 상황에서 global queue는 qos가 달라짐에 따라 각각 다른 queue를 생성하게 되며, 각각 다른 queue이기 때문에 동일한 스레드로 작업을 보낼 가능성이 없게 되는 것
- **main queue에서 `sync`로 작업을 처리하고자 할 경우에도 교착상태가 발생함**

```swift
DispatchQueue.main.sync{
  //에러 발생
}
```

- 위의 경우에는 main queue로 동기적으로 처리할 작업을 메인 스레드로 보내게 되는데, 이럴 경우에도 메인 스레드는 해당 작업이 끝날 때 까지 자원을 반납하지 않을 것이며, 동일한 스레드에 할당된 **`sync`** 작업 또한 자원을 할당받을 수 없어 실행되지 못하기 때문에 교착상태가 발생하는 것